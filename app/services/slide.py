"""Slide generation service — analyse document → JSON slide data.

Orchestrates: provider.generate() + prompt assembly + JSON parsing.
"""

from __future__ import annotations

from collections.abc import Callable

from app.core.json_parser import robust_json_parse
from app.core.log import safe_print
from app.prompts.slide import (
    DETAIL_MODE_INSTRUCTION,
    OVERVIEW_MODE_INSTRUCTION,
    SYSTEM_INSTRUCTION,
    build_custom_instruction_block,
)
from app.providers.registry import get_provider, resolve_provider_keys
from app.services.document import load_document


def analyze_document(
    file_bytes: bytes,
    mime_type: str,
    *,
    api_key: str | None = None,
    api_keys: list[str] | None = None,
    detail_level: str = "Tóm tắt",
    user_instructions: str = "",
    cancel_check: Callable[[], bool] | None = None,
    provider: str = "gemini",
) -> dict:
    """Analyse a document and return structured slide JSON."""

    keys = resolve_provider_keys(provider, api_key, api_keys)

    # Build final system instruction
    mode_block = DETAIL_MODE_INSTRUCTION if detail_level == "Chi tiết" else OVERVIEW_MODE_INSTRUCTION
    custom_block = build_custom_instruction_block(user_instructions)
    final_instruction = SYSTEM_INSTRUCTION + "\n" + mode_block + custom_block

    safe_print(f"Using {detail_level} mode prompt...")

    # For text-only providers, pre-extract document text
    full_prompt = f"Hãy phân tích tài liệu này và tạo cấu trúc bài thuyết trình ({detail_level})."
    extra_text = ""
    if provider in ("openai", "ollama") and file_bytes and mime_type:
        try:
            extra_text = load_document(file_bytes, mime_type)
            full_prompt = f"Nội dung tài liệu:\n{extra_text}\n\n{full_prompt}"
        except Exception as exc:
            raise ValueError(f"Không thể đọc tài liệu: {exc}") from exc

    llm = get_provider(
        provider,
        api_keys=keys,
        base_url=keys[0] if provider == "ollama" and keys and keys[0].startswith("http") else None,
    )

    generated_text, _used_model = llm.generate(
        system=final_instruction,
        prompt=full_prompt,
        cancel_check=cancel_check,
        response_format_json=True,
        temperature=0.7,
        file_bytes=file_bytes if provider == "gemini" else None,
        mime_type=mime_type if provider == "gemini" else None,
    )

    if not generated_text:
        raise ValueError("AI không trả về nội dung.")

    parsed = robust_json_parse(generated_text)

    # Normalise list → dict
    if isinstance(parsed, list):
        safe_print("AI returned a LIST. Wrapping into standard schema...")
        parsed = {"title": "Slide Generated by AI", "slides": parsed}

    # Validate slides
    for i, slide in enumerate(parsed.get("slides", [])):
        content = slide.get("content", [])
        if not content or (isinstance(content, list) and len(content) == 0):
            safe_print(f"WARNING: Slide {i + 1} has EMPTY content.")
            if slide.get("notes"):
                slide["content"] = [slide["notes"]]
            else:
                slide["content"] = ["(Nội dung chưa được trích xuất)"]

    return parsed
