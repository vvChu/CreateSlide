# ── LLM Provider Selection ────────────────────────────────────────────
# Options: "auto", "gemini", "openai", "ollama"
# "auto" picks the best available (ollama > gemini > openai)
DEFAULT_PROVIDER=auto

# ── Google Gemini ─────────────────────────────────────────────────────
# Get yours at: https://aistudio.google.com/
# GOOGLE_API_KEY=AIza...

# ── OpenAI ────────────────────────────────────────────────────────────
# OPENAI_API_KEY=sk-...

# ── Ollama / DGX Spark (local LLM, free) ─────────────────────────────
OLLAMA_BASE_URL=http://localhost:11444/v1
OLLAMA_API_KEY=ollama
OLLAMA_TIMEOUT=600

# ── Generation parameters ────────────────────────────────────────────
AI_RETRY_CYCLES=3
DEFAULT_TEMPERATURE=0.7
MIN_RETRY_DELAY_REMOTE=15.0
MIN_RETRY_DELAY_LOCAL=1.0

# ── Application limits ───────────────────────────────────────────────
MAX_UPLOAD_SIZE_MB=50
SERVER_PORT=32123

# ── Logging ───────────────────────────────────────────────────────────
LOG_FILE=app.log
LOG_MAX_BYTES=5242880
LOG_BACKUP_COUNT=3
